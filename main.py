import requests
import json
import utils
import zipfile
import os
import time
import warnings
import geojson
from pathlib import Path
from shapely.geometry import shape
from pykml import parser
from coord_lookup import Lookup
from pykml.factory import KML_ElementMaker as KML
from lxml import etree, objectify
from requests.packages.urllib3.exceptions import InsecureRequestWarning
from random import randint

lookup = Lookup()
st = time.time()

warnings.simplefilter('ignore',InsecureRequestWarning)

def get_links(link,actualCount,maxCount, index=0, links=[]):
  """
  Turns a single link into a list of links based on the number of objects it contains versus
  the number of objects that can be returned by the API. Only used if more than 1 link is required,
  so we multiply by 4 just to be account for uneven distrobution of locations. 

  Returns: A list of links to download
  """
  req_divisions = round(actualCount / maxCount, 0)
  # Distribution of points is rarely even across the country, so might as well aim high
  divisions = int(req_divisions * 3)

  # Roughly 54 lon degrees between east and west ends of continental US
  offset = round(54 / divisions, 1)

  lon = -125
  top_lat = 49.35
  bot_lat = 24.39
  for i in range(0, divisions):
    lst_geom = [str(lon), str(bot_lat), str(lon+offset), str(top_lat)]
    geom = ','.join(lst_geom)
    links.append(link + f'/query?&where=1=1&geometryType=esriGeometryEnvelope&inSR=4326&geometry={geom}&spatialRel=esriSpatialRelEnvelopeIntersects&outFields=*&f=kmz')
    try:
        #if link_obj["raster"]:
        #    url = links + f'/generateKML?docName=doc&layers={str(layer)}&layerOptions=nonComposite'
        if link_obj["type"] == "geoJSON":
            links.append(link + f'/query?&where=1=1&geometryType=esriGeometryEnvelope&inSR=4326&geometry={geom}&spatialRel=esriSpatialRelEnvelopeIntersects&outFields=*&f=pgeojson')
    except KeyError:
        pass

    lon = lon + offset

  utils.debug('Number of links generated: ' + str(len(links)))
  return links

def split_ids(ids, n):
    for i in range(0, len(ids), n-1):
        yield ids[i:i+n-1]

def get_id_field(link, layer):
    url = link + '/' + str(layer) + '?f=pjson'
    r = requests.get(url, verify=False)
    fields = json.loads(str(r.content, 'utf-8'))['fields']
    id_field = next((x for x in fields if x["type"] == 'esriFieldTypeOID'), 'OBJECTID')
    return id_field['name']


def get_links_by_id(link, layer, maxCount):
    links = []
    url = link + '/' + str(layer) + '/query?where=1=1&returnIdsOnly=true&f=json'
    r = requests.get(url, verify=False)

    ids = json.loads(str(r.content, 'utf-8'))['objectIds']
    id_chunks = list(split_ids(ids, 200))
    id_field = get_id_field(link, layer)
    for chunk in id_chunks:
        formatted_chunk = '(' + ','.join(str(x) for x in chunk) + ')'
       
        try:
            #if link_obj["raster"]:
            #    url = links + f'/generateKML?docName=doc&layers={str(layer)}&layerOptions=nonComposite'
            if link_obj["type"] == "geoJSON":
                links.append(link + '/' + str(layer) + f'/query?&where={id_field}%20IN%20{formatted_chunk}&outFields=*&returnGeometry=true&outSpatialReference=4326&f=pgeojson')
            else:
                links.append(link + '/' + str(layer) + f'/query?where={id_field}%20IN%20{formatted_chunk}&outFields=*&returnGeometry=true&outSpatialReference=4326&f=kmz')
        except ValueError:
            links.append(link + '/' + str(layer) + f'/query?where={id_field}%20IN%20{formatted_chunk}&outFields=*&returnGeometry=true&outSpatialReference=4326&f=kmz')
    utils.debug('Number of links generated by ID: ' + str(len(links)))

    return links



def download(links, name, layer, redownload=True):
    """
    Downloads a single or list of links and names appropriately. 

    Return: A list of file paths created

    download arg is just for dev/troubleshooting, setting it to false will skip redownloading the
    files. Script will fail if they do not already exist.
    """
    paths = []
    if isinstance(links, str):
        url = links + '/' + str(layer) + '/query?where=1=1&outFields=*&f=kmz'
        path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '.kmz'
        try:
            if link_obj["type"] == "geoJSON":
                url = links + '/query?where=1%3D1&objectIds=&f=pgeojson'
                path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '.geoJSON'
            if link_obj["raster"]:
                url = links + f'/generateKML?docName=doc&layers={str(layer)}&layerOptions=nonComposite'

        except KeyError:
            pass


        paths.append(path)
        if (redownload or not os.path.isfile(path)):
            Path("cache/temp/" + name).mkdir(parents=True, exist_ok=True)
            with open(path, 'wb') as output:
                r = requests.get(url, verify=False)
                output.write(r.content)
        else:
                utils.debug(f'Skipping {path} since it already exists')
    elif type(links) == list:
        i = 1

        for link in links:
            r = 0
            path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '_part_' + str(i) + '.kmz'
            try:
                if link_obj["type"] == "geoJSON":
                    url = link + '/query?where=1%3D1&objectIds=&f=pgeojson'
                    path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '_part_' + str(i) + '.geoJSON'
            except KeyError:
                pass
            paths.append(path)
            if (redownload or not os.path.isfile(path)):
                Path("cache/temp/" + name + '/final').mkdir(parents=True, exist_ok=True)
                with open(path, 'wb') as output:
                    utils.progress_bar(f'Downloading part {i} of {len(links)}', i, len(links))
                    r = requests.get(link, verify=False)
                    output.write(r.content)
            else:
                utils.debug(f'Skipping {path} since it already exists')

            i = i + 1

    return paths

def print_child_features(element):
    """ Prints the name of every child node of the given element, recursively """
    if not getattr(element, 'features', None):
        return
    for feature in element.features():
        print(feature.name)
        print_child_features(feature)

def merge(paths, layers):
    """
    Merges multiple KMZ files into 1 file based on a list of paths.
    """
    name_set = set()
    stylemap = []
    dct_features = {}
    feature_count = 0
    if len(paths) == 1:
       # TODO: We should skip the merge process if we only have 1 path
       pass
    name_escaped = parent_kmz_name.replace(' & ', '_').replace('&', '_').replace(' ', '_')


    i = 0
    layer_index = 0
    for layer in paths:
        for path in layer:
            folder_path = path.split('.')[0]

            if link_obj["type"] == "geoJSON":
                k = geojson.geojson_to_kml(path, parent_kmz_name)
            else:
                with zipfile.ZipFile(path, 'r') as zip_ref:
                    zip_ref.extractall(folder_path)

                os.system('cp ' + folder_path + '/*.png ' + 'cache/temp/' + name_escaped + '/final/ 2>/dev/null')
                os.system('cp ' + folder_path + '/*.xsl ' + 'cache/temp/' + name_escaped + '/final/ 2>/dev/null')

                with open(folder_path + '/doc.kml', 'r') as kml_file:
                    k = parser.parse(kml_file).getroot()

                try:
                    k.NetworkLink.name = KML.name(lnk_name)
                    return(k.NetworkLink, stylemap)
                except AttributeError:
                    pass

            k_doc = k.Document
            # Make Style IDs unique so they don't conflict once merged
            for style in k.findall('.//{http://www.opengis.net/kml/2.2}Style'):
                style.set('id', style.attrib.get('id') + lnk_name_safe + 'pt' + str(i))
                stylemap.append(style)

            for mark in k.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
                try:
                    mark.set('id', mark.attrib.get('id') + 'f' + str(i) + 'l' + str(layer_index) + str(randint(1000, 9999)))
                except TypeError:
                    # Give a random ID if none currently exists (geoJSON)
                    mark.set('id', 'ID_' + str(randint(1000,9999)) + 'f' + str(i) + 'l' + str(layer_index) + str(randint(1000, 9999)))

            if link_obj["sort_by_state"]:

                for mark in k.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
                    mark.styleUrl = mark.styleUrl + lnk_name_safe + 'pt' + str(i)
                    for coords in mark.find('.//{http://www.opengis.net/kml/2.2}coordinates'):
                        # This grabs the first set of coordinates for use determining state.
                        # Larger objects may span multiple states
                        try:
                            lon = coords.text.split('\n')[1].split(',')[0]
                            lat = coords.text.split('\n')[1].split(',')[1]
                        except IndexError:
                            lon = coords.text.split(',')[0]
                            lat = coords.text.split(',')[1]

                        # Right now, we only use FIPS number to identify state if it's
                        # the only thing in the description
                        try:
                            if 0 <= int(mark.description) <= 56:
                                state = lookup.state(lat, lon, int(mark.description))
                            else:
                                state = lookup.state(lat, lon)
                        except ValueError:
                            state = lookup.state(lat, lon)


                        #for style in mark.findall('.//{http://www.opengis.net/kml/2.2}Style'):
                            #style.set('id', style.attrib.get('id') + 'pt' + str(i))
                        # Can't get the API to stop returning duplicates, so we check manually
                        #if feature.name not in name_set:
                        try:
                            dct_features[layers[layer_index]][state].append(mark)
                            feature_count = feature_count + 1
                            #name_set.add(feature.name)
                        except KeyError:
                            try:
                                dct_features[layers[layer_index]][state] = []
                            except KeyError:
                                dct_features[layers[layer_index]] = {}
                                dct_features[layers[layer_index]][state] = []
                            dct_features[layers[layer_index]][state].append(mark)
                            feature_count = feature_count + 1
                            #name_set.add(feature.name)

                        if (feature_count % 100 == 0):
                            utils.progress_bar(f'Processing states', feature_count, len(k.findall('.//{http://www.opengis.net/kml/2.2}Placemark')) * len(paths))

                    #except AttributeError:
                    #for feature in list(list(k_doc.features())[0].features()):
                    #    if feature.geometry.geom_type == 'LineString':
                    #        # Grab the first point in the line for categorization
                    #        lon = feature.geometry.coords[0][0]
                    #        lat = feature.geometry.coords[0][1]
                    #    elif feature.geometry.geom_type == 'MultiLineString':
                    #        # Grab the lower left corner of the bounding box since it's 
                    #        # easier than parsing out the lines
                    #        lon = feature.geometry.bounds[1]
                    #        lon = feature.geometry.bounds[0]
                    #    try:
                    #        state = lookup.state(lat, lon)
                    #    except UnboundLocalError:
                    #        # Some KML maps don't need to be split by state, i.e. they don't have POIS, just shapes (weather)
                    #        pass
                    #    feature.styleUrl = feature.styleUrl + 'pt' + str(i)
                    #    # Can't get the API to stop returning duplicates, so we check manually

                    #    if feature.name not in name_set:
                    #        try:
                    #            dct_features[state].append(feature)
                    #            feature_count = feature_count + 1
                    #            name_set.add(feature.name)
                    #        except KeyError:
                    #            dct_features[state] = []
                    #            dct_features[state].append(feature)
                    #            feature_count = feature_count + 1
                    #            name_set.add(feature.name)
        
                #except TypeError:
                #    pass

            elif link_obj["sort_by_layer"]:
                utils.debug("Appending layer " + str(i) + " to dct_features")
                dct_features = append_to_layers(dct_features, k_doc, layers[layer_index], feature_count, i)

            i = i + 1
        layer_index = layer_index + 1

    if link_obj["sort_by_state"]:    
        utils.debug("Combining States")
        kml_folder = combine_states(dct_features, link_obj, stylemap)
    
    elif link_obj["sort_by_layer"]:
        utils.debug("Combining layers")
        kml_folder = combine_layers(dct_features, k_doc, link_obj, stylemap, layers)
    return(kml_folder, stylemap)

def write_kml(kml_doc, parent_kmz_name):
    objectify.deannotate(kml_doc, xsi_nil=True)
    etree.cleanup_namespaces(kml_doc)

    parser.Schema("ogckml22.xsd").assertValid(kml_doc)
    assert(parser.Schema("kml22gx.xsd").validate(kml_doc))
    #final_kml_text = kml_doc.to_string(prettyprint=True)
    final_kml_text = etree.tostring(kml_doc, pretty_print=True)
    output = Path('cache/temp/' + parent_kmz_name_safe + "/final/doc.kml")
    output.write_bytes(final_kml_text)
    zip_kml(parent_kmz_name_safe)


def append_to_layers(dct_features, k_doc, layer, feature_count, i):
    """ Adds a list of features to a 'layer' object in dct_features. """
    #for feature in list(list(k_doc.features())[0].features()):
    for placemark in k_doc.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
        placemark.styleUrl = placemark.styleUrl + lnk_name_safe + 'pt' + str(i)
        try:
            dct_features[layer].append(placemark)
            feature_count = feature_count + 1

        except KeyError:
            dct_features[layer] = []
            dct_features[layer].append(placemark)
            feature_count = feature_count + 1
    return(dct_features)

def append_to_states(dct_features, k_doc, state, i):
    """ Adds a list of features to a 'layer' object in dct_features. """

    for placemark in k_doc.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
        placemark.styleUrl = placemark.styleUrl + lnk_name_safe + 'pt' + str(i)
        try:
            dct_features[state].append(placemark)

        except KeyError:
            dct_features[state] = []
            dct_features[state].append(placemark)
    return(dct_features)


def combine_states(features, link_obj, stylemap):
    """ Turns a dictionary of multiple states into 1 KML object with separate folders for each state. """

    parent_folder = KML.Folder(
        KML.name(lnk_name),
        KML.description(link_obj["description"]))
    i = 0
    for style in stylemap:
            parent_folder.append(style)

    for layer_obj in features:
        if len(link_obj["layer_names"]) > 1:
            layer_folder = KML.Folder(KML.name(link_obj["layer_names"][str(layers[i])]),
                                    KML.description('Description'))
        else:
            # Bypass separate layer folders if there's only 1 layer
            layer_folder = parent_folder
        for state in features[layer_obj]:
            state_folder = KML.Folder(KML.name(state))
            for mark in features[layer_obj][state]:
                state_folder.append(mark)
            layer_folder.append(state_folder)
        if len(link_obj["layer_names"]) > 1:
            parent_folder.append(layer_folder)
        i = i + 1

    return parent_folder


def combine_layers(features, k_doc, link_obj, stylemap, layers):
    """ Turns a dictionary of multiple layers into 1 kml object with 1 folder per layer """

    parent_folder = KML.Folder( KML.name(lnk_name), KML.description(link_obj["description"]))
    i = 0
    for style in stylemap:
            parent_folder.append(style)
    for layer_obj in features:
        layer_folder = KML.Folder(KML.name(link_obj["layer_names"][str(layers[i])]),
                                  KML.description('Description'))
        
        for mark in features[layer_obj]:
            layer_folder.append(mark)
        parent_folder.append(layer_folder)
        i = i + 1
    return parent_folder


#def make_top_level_doc(folders, folder_cfg, name, description, lst_styles):
def make_top_level_doc(folders, folder_cfg, name, description, styles):

    tld = KML.kml(KML.Document(
        KML.name(name),
        KML.description(description)
    ))
    for style in styles:
        tld.Document.append(style)
    i = 0
    for folder in folders:
        i = i + 1
        tld.Document.append(folder)

    return tld


def zip_kml(name):
    """
    Takes the name of a folder and zips the contents into a .kmz
    """
    #name = name.replace(' & ', '_').replace('&', '_').replace(' ', '_')
    with zipfile.ZipFile('cache/temp/' + name + '.kmz', 'w', zipfile.ZIP_DEFLATED) as zip:
        os.chdir('cache/temp/' + name + '/final')
        for filename in os.listdir('.'):
            zip.write(filename)
        os.chdir('../../../..')
        os.system('mv cache/temp/' + name + '.kmz' + ' cache/kmz/')
    

if __name__ == "__main__":
    all_styles = []
    keep_chars = ('_')
    with open('links.json', 'r') as linksfile:
        for ind_file in json.load(linksfile, cls=utils.JSONWithCommentsDecoder)["files"]:
            print("=" * 80)
            print("Starting top level file " + ind_file["name"])
            print("=" * 80)
            second_level_folders = []
            lst_link = ind_file["links"]
            parent_kmz_name = ind_file["name"]
            parent_kmz_name_safe = "".join(c for c in parent_kmz_name.replace(' & ', '_') if c.isalnum() or c in keep_chars).rstrip()
            parent_kmz_description = ind_file["description"]

            os.system('rm -r ' + 'cache/temp/' + parent_kmz_name_safe + '/final')
            os.system('mkdir -p ' + 'cache/temp/' + parent_kmz_name_safe + '/final')

            for link_obj in lst_link:
                link = link_obj["link"]
                layers = link_obj["layers"]
                lnk_name = link_obj["name"]
                lnk_name_safe = "".join(c for c in lnk_name.replace(' & ', '_') if c.isalnum() or c in keep_chars).rstrip()
                print("Starting second level link " + lnk_name)
                try:
                    layer_names = link_obj["layer_suffix"]
                except KeyError:
                    pass
                paths = []

                os.system('mkdir -p ' + 'cache/temp/' + parent_kmz_name_safe)
                if link_obj["enabled"]:
                    layer_index = 0
                    for layer in layers:
                        # Get max count to compare to actual count
                        max_count_url = link + '?f=pjson'
                        r = requests.get(max_count_url, verify=False)
                        max_count = json.loads(str(r.content, 'utf-8'))['maxRecordCount']

                        url = link + '/' + str(layer) + '/query?where=1=1&outFields=*&returnCountOnly=true&f=json'
                        success = False
                        tries = 0
                        # TODO: Create get_with_retry method in utils
                        while not success:
                            r = requests.get(url, verify=False)
                            if (r.status_code == 200 or tries == 2):
                                success = True
                            else:
                                tries = tries + 1

                        try:
                            actual_count = json.loads(str(r.content, 'utf-8'))['count']
                        except (KeyError, json.decoder.JSONDecodeError):
                            # If we can't get a count, it's probably a network/raster layer
                            actual_count = 1
                        utils.debug(f'Counts for {lnk_name} layer {str(layer)}: Max={str(max_count)}, Actual={str(actual_count)}')
                        if actual_count > max_count:
                            links = get_links_by_id(link, str(layer),max_count)
                            #paths.extend(download(links, lnk_name_safe, layer))
                            paths.append(download(links, lnk_name_safe, layer))
                        else:
                            paths.append(download(link, lnk_name_safe, layer))
                        

                    if len(paths) > 0:
                        objects, styles = merge(paths, layers)
                        all_styles.extend(styles)
                        second_level_folders.append(objects)
            tld = make_top_level_doc(second_level_folders, lst_link, parent_kmz_name, parent_kmz_description, all_styles)
            write_kml(tld, parent_kmz_name)

elapsed_time = time.time() - st
print('Execution time: ', time.strftime("%H:%M:%S", time.gmtime(elapsed_time)))

with open('last_run_time.txt', 'w') as time_file:
    time_file.write(time.strftime('%Y-%m-%dT%H:%M:%S'))

