import requests
import json
import utils
import zipfile
import os
import time
import warnings
import geojson
from pathlib import Path
from shapely.geometry import shape
from pykml import parser
from coord_lookup import Lookup
from pykml.factory import KML_ElementMaker as KML
from lxml import etree, objectify
from requests.packages.urllib3.exceptions import InsecureRequestWarning
from random import randint

lookup = Lookup()
st = time.time()

warnings.simplefilter('ignore',InsecureRequestWarning)

def get_links(link,actualCount,maxCount, index=0, links=[]):
  """
  Turns a single link into a list of links based on the number of objects it contains versus
  the number of objects that can be returned by the API. Only used if more than 1 link is required,
  so we multiply by 4 just to be account for uneven distrobution of locations. 

  Returns: A list of links to download
  """
  req_divisions = round(actualCount / maxCount, 0)
  # Distribution of points is rarely even across the country, so might as well aim high
  divisions = int(req_divisions * 3)

  # Roughly 54 lon degrees between east and west ends of continental US
  offset = round(54 / divisions, 1)

  lon = -125
  top_lat = 49.35
  bot_lat = 24.39
  for i in range(0, divisions):
    lst_geom = [str(lon), str(bot_lat), str(lon+offset), str(top_lat)]
    geom = ','.join(lst_geom)
    links.append(link + f'/query?&where=1=1&geometryType=esriGeometryEnvelope&inSR=4326&geometry={geom}&spatialRel=esriSpatialRelEnvelopeIntersects&outFields=*&f=kmz')
    try:
        #if link_obj["raster"]:
        #    url = links + f'/generateKML?docName=doc&layers={str(layer)}&layerOptions=nonComposite'
        if link_obj["type"] == "geoJSON":
            links.append(link + f'/query?&where=1=1&geometryType=esriGeometryEnvelope&inSR=4326&geometry={geom}&spatialRel=esriSpatialRelEnvelopeIntersects&outFields=*&f=pgeojson')
    except KeyError:
        pass

    lon = lon + offset

  utils.debug('Number of links generated: ' + str(len(links)))
  return links

def split_ids(ids, n):
    for i in range(0, len(ids), n-1):
        yield ids[i:i+n-1]

def get_id_field(link, layer):
    url = link + '/' + str(layer) + '?f=pjson'
    r = requests.get(url, verify=False)
    fields = json.loads(str(r.content, 'utf-8'))['fields']
    id_field = next((x for x in fields if x["type"] == 'esriFieldTypeOID'), 'OBJECTID')
    return id_field['name']


def get_links_by_id(link, layer, maxCount):
    """
    Splits a single URL into a set based on the IDs of the objects it contains. maxCount may be greater
    than the number of IDs we can fit into a single URL before exceeding the max length, which is why it 
    isn't used at the moment.

    Args:
        link: Single link to be split
        layer: Layer index
        maxCount: Maximum number of IDs to include in a single download

    Returns:
        A list of links for downloading
    """
    links = []
    url = link + '/' + str(layer) + '/query?where=1=1&returnIdsOnly=true&f=json'
    r = utils.dl_with_retry(url)
    ids = json.loads(str(r, 'utf-8'))['objectIds']
    id_chunks = list(split_ids(ids, 200))
    id_field = get_id_field(link, layer)
    for chunk in id_chunks:
        formatted_chunk = '(' + ','.join(str(x) for x in chunk) + ')'
       
        try:
            #if link_obj["raster"]:
            #    url = links + f'/generateKML?docName=doc&layers={str(layer)}&layerOptions=nonComposite'
            if link_obj["type"] == "geoJSON":
                #links.append(link + '/' + str(layer) + f'/query?&where={id_field}%20IN%20{formatted_chunk}&outFields=*&returnGeometry=true&outSpatialReference=4326&f=pgeojson')
                links.append(link + '/' + str(layer) + f'/query?&where={id_field}%20IN%20{formatted_chunk}&outFields=*&returnGeometry=true&outSpatialReference=4326&f=geojson')
            if link_obj["type"] == "JSON":
                links.append(link + '/' + str(layer) + f'/query?&where={id_field}%20IN%20{formatted_chunk}&outFields=*&returnGeometry=true&outSpatialReference=4326&f=pjson')

            else:
                links.append(link + '/' + str(layer) + f'/query?where={id_field}%20IN%20{formatted_chunk}&f=kmz')
        except ValueError:
            links.append(link + '/' + str(layer) + f'/query?where={id_field}%20IN%20{formatted_chunk}&f=kmz')
    utils.debug('Number of links generated by ID: ' + str(len(links)))

    return links



def download(links, name, layer, redownload=True):
    """
    Downloads a single or list of links and names appropriately. 

    Args:
        links: Either a single link string or a list of links to download
        name: The string used to name the output files
        layer: Name of the layer you're downloading, included in output file names
        redownload: Disable to skip downloading files that already exist. Useful for speeding up testing.

    Returns: 
        A list of file paths created
    """
    paths = []
    print(f"Downloading {name} layer {layer}")
    if isinstance(links, str):
        url = links + '/' + str(layer) + '/query?where=1=1&outFields=*&f=kmz'
        path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '.kmz'
        try:
            if link_obj["type"] == "geoJSON":
                #url = links + '/query?where=1%3D1&objectIds=&f=pgeojson'
                url = links + '/' + str(layer) + '/query?where=1%3D1&objectIds=&f=geojson'
                path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '.geoJSON'
            if link_obj["type"] == "JSON":
                url = links + '/' + str(layer) + '/query?where=1%3D1&objectIds=&outFields=*&f=pjson'
                path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '.JSON'
            if link_obj["type"] == "raster":
                url = links + f'/generateKML?docName=doc&layers={str(layer)}&layerOptions=nonComposite'

        except KeyError:
            print("KeyError String")
            pass


        paths.append(path)
        if (redownload or not os.path.isfile(path)):
            Path("cache/temp/" + name).mkdir(parents=True, exist_ok=True)
            with open(path, 'wb') as output:
                r = requests.get(url, verify=False)
                output.write(r.content)
        else:
                utils.debug(f'Skipping {path} since it already exists')
    elif type(links) == list:
        i = 1

        for link in links:
            r = 0
            path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '_part_' + str(i) + '.kmz'
            try:
                if link_obj["type"] == "geoJSON":
                    url = link + '/query?where=1%3D1&objectIds=&f=pgeojson'
                    path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '_part_' + str(i) + '.geoJSON'
                if link_obj["type"] == "JSON":
                    url = link + '/query?where=1%3D1&objectIds=&f=json'
                    path = 'cache/temp/' + name + '/' + name + '_layer' + str(layer) + '_part_' + str(i) + '.JSON'
            except KeyError:
                print("KeyError")
                pass
            paths.append(path)
            if (redownload or not os.path.isfile(path)):
                Path("cache/temp/" + name + '/final').mkdir(parents=True, exist_ok=True)
                with open(path, 'wb') as output:
                    utils.progress_bar(f'Downloading part {i} of {len(links)}', i, len(links))
                    r = utils.dl_with_retry(link)
                    output.write(r)
            else:
                utils.debug(f'Skipping {path} since it already exists')

            i = i + 1

    return paths

def print_child_features(element):
    """ Prints the name of every child node of the given element, recursively """
    if not getattr(element, 'features', None):
        return
    for feature in element.features():
        print(feature.name)
        print_child_features(feature)

def merge(paths, layers):
    """
    Merges multiple KMZ files into 1 file based on a list of paths. Additionally,
    sets unique IDs for placemarks, styles, and styleUrls to avoid ID conflicts

    Args:
        paths: List of KMZ files to combine
        layers: List of layers, used to name subfolders

    Returns:
        kml_folder: A single KML folder with all content from paths
        stylemap: List of styles from all paths
    """

    stylemap = []
    dct_features = {}
    feature_count = 0
    if len(paths) == 1:
       # TODO: We should skip the merge process if we only have 1 path
       pass
    name_escaped = parent_kmz_name.replace(' & ', '_').replace('&', '_').replace(' ', '_')


    i = 0
    layer_index = 0
    for layer in paths:
        for path in layer:
            folder_path = path.split('.')[0]
            
            if link_obj["name"] == "Air Quality Index":
                k = geojson.aqi(path,parent_kmz_name)
            elif link_obj["type"] == "geoJSON":
                k = geojson.geojson_to_kml(path, parent_kmz_name)
            elif link_obj["type"] == "JSON":
                k = geojson.geojson_to_kml(path, parent_kmz_name)
            else:
                print(link_obj["type"])
                with zipfile.ZipFile(path, 'r') as zip_ref:
                    zip_ref.extractall(folder_path)

                os.system('cp ' + folder_path + '/*.png ' + 'cache/temp/' + parent_kmz_name_safe + '/final/ 2>/dev/null')
                os.system('cp ' + folder_path + '/*.xsl ' + 'cache/temp/' + parent_kmz_name_safe + '/final/ 2>/dev/null')

                with open(folder_path + '/doc.kml', 'r') as kml_file:
                    try:
                        k = parser.parse(kml_file).getroot()
                    except etree.XMLSyntaxError:
                        print("Caught a syntax error in {folder_path}")
                        # Initialize an empty KML folder/doc to skip the broken file. 
                        # TODO: Validate/fix KML files before parsing. 
                        # USGS Trails layer has '<' in at least 1 trail name, which is why we do this.
                        k = KML.folder(KML.Document())
                        #return(KML.folder(), stylemap)


                try:
                    k.NetworkLink.name = KML.name(lnk_name)
                    return(k.NetworkLink, stylemap)
                except AttributeError:
                    pass

            k_doc = k.Document
            # Make Style IDs unique so they don't conflict once merged
            for style in k.findall('.//{http://www.opengis.net/kml/2.2}Style'):
                style.set('id', style.attrib.get('id') + lnk_name_safe + 'pt' + str(i))
                stylemap.append(style)

            for mark in k.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
                try:
                    mark.set('id', mark.attrib.get('id') + 'f' + str(i) + 'l' + str(layer_index) + str(randint(1000, 999999)))
                except TypeError:
                    # Give a random ID if none currently exists (geoJSON)
                    mark.set('id', 'ID_' + str(randint(1000,9999)) + 'f' + str(i) + 'l' + str(layer_index) + str(randint(1000, 9999)))

            if link_obj["sort_by_state"]:

                for mark in k.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
                    mark.styleUrl = mark.styleUrl + lnk_name_safe + 'pt' + str(i)
                    for coords in mark.find('.//{http://www.opengis.net/kml/2.2}coordinates'):
                        # This grabs the first set of coordinates for use determining state.
                        # Larger objects may span multiple states
                        try:
                            lon = coords.text.split('\n')[1].split(',')[0]
                            lat = coords.text.split('\n')[1].split(',')[1]
                        except IndexError:
                            lon = coords.text.split(',')[0]
                            lat = coords.text.split(',')[1]

                        # Right now, we only use FIPS number to identify state if it's
                        # the only thing in the description
                        try:
                            if 0 <= int(mark.description) <= 56:
                                state = lookup.state(lat, lon, int(mark.description))
                            else:
                                state = lookup.state(lat, lon)
                        except (ValueError, AttributeError):
                            state = lookup.state(lat, lon)

                        try:
                            dct_features[layers[layer_index]][state].append(mark)
                            feature_count = feature_count + 1
                        except KeyError:
                            try:
                                dct_features[layers[layer_index]][state] = []
                            except KeyError:
                                dct_features[layers[layer_index]] = {}
                                dct_features[layers[layer_index]][state] = []
                            dct_features[layers[layer_index]][state].append(mark)
                            feature_count = feature_count + 1

                        if (feature_count % 100 == 0):
                            utils.progress_bar(f'Processing states', feature_count, len(k.findall('.//{http://www.opengis.net/kml/2.2}Placemark')) * len(paths))

            elif link_obj["sort_by_layer"]:
                utils.debug("Appending layer " + str(i) + " to dct_features")
                dct_features = append_to_layers(dct_features, k_doc, layers[layer_index], feature_count, i)

            i = i + 1
        layer_index = layer_index + 1

    if link_obj["sort_by_state"]:    
        utils.debug("Combining States")
        kml_folder = combine_states(dct_features, link_obj, stylemap)
    
    elif link_obj["sort_by_layer"]:
        utils.debug("Combining layers")
        kml_folder = combine_layers(dct_features, k_doc, link_obj, stylemap, layers)
    return(kml_folder, stylemap)

def write_kml(kml_doc, parent_kmz_name_safe):
    """
    Validate a KML document, write it out, and call zip_kml to create the KMZ

    Args:
        kml_doc: Full KML doc object for writing
        parent_kmz_name_safe: Filename for folder path, must not include spaces, &'s, etc.
    """
    objectify.deannotate(kml_doc, xsi_nil=True)
    etree.cleanup_namespaces(kml_doc)

    parser.Schema("ogckml22.xsd").assertValid(kml_doc)
    assert(parser.Schema("kml22gx.xsd").validate(kml_doc))
    #final_kml_text = kml_doc.to_string(prettyprint=True)
    final_kml_text = etree.tostring(kml_doc, pretty_print=True)
    output = Path('cache/temp/' + parent_kmz_name_safe + "/final/doc.kml")
    output.write_bytes(final_kml_text)
    zip_kml(parent_kmz_name_safe)


def append_to_layers(dct_features, k_doc, layer, feature_count, i):
    """ Adds a list of features to a 'layer' object in dct_features. 
    
    Args:
        dct_features: Contains keys for each layer, holds placemarks for addition to a KML object
        k_doc: KML object that contains the source features we want to append
        layer: Layer name, used as dictionary key
        feature_count: Index used to track total features
        i: index used to differentiate styles from multiple layers

    Returns:
        dct_features: Same as Arg dct_features
    """
    #for feature in list(list(k_doc.features())[0].features()):
    for placemark in k_doc.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
        placemark.styleUrl = placemark.styleUrl + lnk_name_safe + 'pt' + str(i)
        try:
            dct_features[layer].append(placemark)
            feature_count = feature_count + 1

        except KeyError:
            dct_features[layer] = []
            dct_features[layer].append(placemark)
            feature_count = feature_count + 1
    if len(k_doc.findall('.//{http://www.opengis.net/kml/2.2}Placemark')) == 0:
        dct_features[layer] = []
    return(dct_features)

def append_to_states(dct_features, k_doc, state, i):
    """ Adds a list of features to a 'layer' object in dct_features. """

    for placemark in k_doc.findall('.//{http://www.opengis.net/kml/2.2}Placemark'):
        placemark.styleUrl = placemark.styleUrl + lnk_name_safe + 'pt' + str(i)
        try:
            dct_features[state].append(placemark)

        except KeyError:
            dct_features[state] = []
            dct_features[state].append(placemark)
    return(dct_features)


def combine_states(features, link_obj, stylemap):
    """ Turns a dictionary of multiple states into 1 KML object with separate folders for each state. """

    parent_folder = KML.Folder(
        KML.name(lnk_name),
        KML.description(link_obj["description"]))
    i = 0
    for style in stylemap:
            parent_folder.append(style)

    for layer_obj in features:
        if len(link_obj["layer_names"]) > 1:
            layer_folder = KML.Folder(KML.name(link_obj["layer_names"][str(layers[i])]),
                                    KML.description('Description'))
        else:
            # Bypass separate layer folders if there's only 1 layer
            layer_folder = parent_folder


        for state in features[layer_obj]:
            state_folder = KML.Folder(KML.name(state))
            for mark in features[layer_obj][state]:
                state_folder.append(mark)
            layer_folder.append(state_folder)
        if len(link_obj["layer_names"]) > 1:
            parent_folder.append(layer_folder)
        i = i + 1

    return parent_folder


def combine_layers(features, k_doc, link_obj, stylemap, layers):
    """ Turns a dictionary of multiple layers into 1 kml object with 1 folder per layer """

    parent_folder = KML.Folder( KML.name(lnk_name), KML.description(link_obj["description"]))
    i = 0
    for style in stylemap:
            parent_folder.append(style)
    for layer_obj in features:
        layer_folder = KML.Folder(KML.name(link_obj["layer_names"][str(layers[i])]),
                                  KML.description('Description'))
        
        for mark in features[layer_obj]:
            layer_folder.append(mark)
        parent_folder.append(layer_folder)
        i = i + 1
    return parent_folder


def make_top_level_doc(folders, folder_cfg, name, description, styles):

    tld = KML.kml(KML.Document(
        KML.name(name),
        KML.description(description)
    ))
    for style in styles:
        tld.Document.append(style)
    i = 0
    for folder in folders:
        i = i + 1
        tld.Document.append(folder)

    return tld


def zip_kml(name):
    """
    Takes the name of a folder and zips the contents into a .kmz
    """
    with zipfile.ZipFile('cache/temp/' + name + '.kmz', 'w', zipfile.ZIP_DEFLATED) as zip:
        os.chdir('cache/temp/' + name + '/final')
        for filename in os.listdir('.'):
            zip.write(filename)
    os.chdir('../../../..')
    os.system('pwd')
    os.system('mv cache/temp/' + name + '.kmz' + ' cache/kmz/')
    

if __name__ == "__main__":
    all_styles = []
    keep_chars = ('_')
    with open('links.json', 'r') as linksfile:
        for ind_file in json.load(linksfile, cls=utils.JSONWithCommentsDecoder)["files"]:
            print("=" * 80)
            print("Starting top level file " + ind_file["name"])
            print("=" * 80)
            second_level_folders = []
            lst_link = ind_file["links"]
            parent_kmz_name = ind_file["name"]
            parent_kmz_name_safe = "".join(c for c in parent_kmz_name.replace(' & ', '_') if c.isalnum() or c in keep_chars).rstrip()
            parent_kmz_description = ind_file["description"]

            os.system('rm -r ' + 'cache/temp/' + parent_kmz_name_safe + '/final')
            os.system('mkdir -p ' + 'cache/temp/' + parent_kmz_name_safe + '/final')

            for link_obj in lst_link:
                link = link_obj["link"]
                layers = link_obj["layers"]
                lnk_name = link_obj["name"]
                lnk_name_safe = "".join(c for c in lnk_name.replace(' & ', '_') if c.isalnum() or c in keep_chars).rstrip()
                print("Starting second level link " + lnk_name)
                try:
                    layer_names = link_obj["layer_suffix"]
                except KeyError:
                    pass
                paths = []

                os.system('mkdir -p ' + 'cache/temp/' + parent_kmz_name_safe)
                if link_obj["enabled"]:
                    layer_index = 0
                    for layer in layers:
                        # Get max count to compare to actual count
                        max_count_url = link + '?f=pjson'
                        r = requests.get(max_count_url, verify=False)
                        max_count = json.loads(str(r.content, 'utf-8'))['maxRecordCount']

                        url = link + '/' + str(layer) + '/query?where=1=1&outFields=*&returnCountOnly=true&f=json'
                        success = False
                        tries = 0
                        # TODO: Create get_with_retry method in utils
                        while not success:
                            r = requests.get(url, verify=False)
                            if (r.status_code == 200 or tries == 2):
                                success = True
                            else:
                                tries = tries + 1

                        try:
                            actual_count = json.loads(str(r.content, 'utf-8'))['count']
                        except (KeyError, json.decoder.JSONDecodeError):
                            # If we can't get a count, it's probably a network/raster layer
                            actual_count = 1
                        utils.debug(f'Counts for {lnk_name} layer {str(layer)}: Max={str(max_count)}, Actual={str(actual_count)}')
                        if actual_count > max_count:
                            links = get_links_by_id(link, str(layer),max_count)
                            paths.append(download(links, lnk_name_safe, layer))
                        else:
                            paths.append(download(link, lnk_name_safe, layer))
                        

                    if len(paths) > 0:
                        objects, styles = merge(paths, layers)
                        all_styles.extend(styles)
                        second_level_folders.append(objects)
            tld = make_top_level_doc(second_level_folders, lst_link, parent_kmz_name, parent_kmz_description, all_styles)
            write_kml(tld, parent_kmz_name_safe)

elapsed_time = time.time() - st
print('Execution time: ', time.strftime("%H:%M:%S", time.gmtime(elapsed_time)))

with open('last_run_time.txt', 'w') as time_file:
    time_file.write(time.strftime('%Y-%m-%dT%H:%M:%S'))

